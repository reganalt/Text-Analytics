{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Regan Alt\n",
    "### Date: April 25th, 2021\n",
    "### Text Analytics Assignment 3 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm one of the 30,000 but it's not working ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0</td>\n",
       "      <td>Damien Morton quoted:\\n\\n&gt;W3C approves HTML 4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>0</td>\n",
       "      <td>On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>0</td>\n",
       "      <td>Once upon a time, Manfred wrote :\\n\\n\\n\\n&gt; I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>0</td>\n",
       "      <td>If you run Pick, and then use the \"New FTOC\" b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CATEGORY                                            MESSAGE\n",
       "0            1  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...\n",
       "1            1  ATTENTION: This is a MUST for ALL Computer Use...\n",
       "2            1  This is a multi-part message in MIME format.\\n...\n",
       "3            1  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...\n",
       "4            1  This is the bottom line.  If you can GIVE AWAY...\n",
       "...        ...                                                ...\n",
       "5791         0  I'm one of the 30,000 but it's not working ver...\n",
       "5792         0  Damien Morton quoted:\\n\\n>W3C approves HTML 4 ...\n",
       "5793         0  On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...\n",
       "5794         0  Once upon a time, Manfred wrote :\\n\\n\\n\\n> I w...\n",
       "5795         0  If you run Pick, and then use the \"New FTOC\" b...\n",
       "\n",
       "[5796 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"Spam Email.csv\", usecols=[\"CATEGORY\", \"MESSAGE\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataset\n",
    "#data = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : [======] : Completed"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dear homeown interest rate are at their lowest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>attent thi is a must for all comput user new s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thi is a multi part messag in mime format next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>import inform the new domain name are final av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>thi is the bottom line if you can give away cd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY                                            MESSAGE\n",
       "0         1  dear homeown interest rate are at their lowest...\n",
       "1         1  attent thi is a must for all comput user new s...\n",
       "2         1  thi is a multi part messag in mime format next...\n",
       "3         1  import inform the new domain name are final av...\n",
       "4         1  thi is the bottom line if you can give away cd..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove non alphabets\n",
    "remove_non_alphabets = lambda x: re.sub(r'[^a-zA-Z]',' ',x)\n",
    "\n",
    "# token alphabets-only list\n",
    "tokenize = lambda x: word_tokenize(x)\n",
    "\n",
    "# assign ps to a lambda function to run on each line of value\n",
    "ps = PorterStemmer()\n",
    "stem = lambda w: [ ps.stem(x) for x in w ]\n",
    "\n",
    "# assign lemmatizer to a lambda function to run on each line of value\n",
    "lemmatizer2 = WordNetLemmatizer()\n",
    "lemmatizer = lambda x: [ lemmatizer2.lemmatize(word) for word in x ]\n",
    "\n",
    "# apply all above methods to the column ''\n",
    "print('Processing : [=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(remove_non_alphabets)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(tokenize)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(stem)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(lemmatizer)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(lambda x: ' '.join(x))\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].str.lower()\n",
    "print('] : Completed', end='')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-Train test sets\n",
    "# split to 30 percent test data and 70 percent train data\n",
    "# labels can be seen as y, an dependent variable\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(data[\"MESSAGE\"],\n",
    "                                                                        data[\"CATEGORY\"],\n",
    "                                                                        test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: \n",
    "## 1) Compare 3 Feature Representations\n",
    "### binary vs frequency vs tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construct features for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary: Bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing good/bad words with Bing Lius dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " -4,\n",
       " 0,\n",
       " -8,\n",
       " -5,\n",
       " -7,\n",
       " -5,\n",
       " -2,\n",
       " -6,\n",
       " -3,\n",
       " -3,\n",
       " -8,\n",
       " -1,\n",
       " -8,\n",
       " -8,\n",
       " -6,\n",
       " -2,\n",
       " -5,\n",
       " -2,\n",
       " -4,\n",
       " -5,\n",
       " -1,\n",
       " -4,\n",
       " -7,\n",
       " 0,\n",
       " -3,\n",
       " -4,\n",
       " 3,\n",
       " -8,\n",
       " -12,\n",
       " -2,\n",
       " -6,\n",
       " -9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " -3,\n",
       " -4,\n",
       " -3,\n",
       " 1,\n",
       " -2,\n",
       " -5,\n",
       " -5,\n",
       " -2,\n",
       " -6,\n",
       " -7,\n",
       " -1,\n",
       " -15,\n",
       " 0,\n",
       " -16,\n",
       " -4,\n",
       " -2,\n",
       " -6,\n",
       " -1,\n",
       " -14,\n",
       " -1,\n",
       " 1,\n",
       " -7,\n",
       " 3,\n",
       " -5,\n",
       " -6,\n",
       " -3,\n",
       " -5,\n",
       " 4,\n",
       " -2,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -4,\n",
       " 1,\n",
       " -7,\n",
       " -2,\n",
       " -2,\n",
       " -6,\n",
       " 2,\n",
       " -8,\n",
       " -10,\n",
       " -2,\n",
       " -17,\n",
       " -2,\n",
       " -2,\n",
       " -8,\n",
       " -3,\n",
       " -6,\n",
       " 2,\n",
       " 3,\n",
       " -3,\n",
       " -1,\n",
       " -3,\n",
       " -1,\n",
       " -3,\n",
       " -14,\n",
       " 0,\n",
       " -10,\n",
       " -5,\n",
       " -9,\n",
       " 0,\n",
       " 3,\n",
       " -4,\n",
       " -7,\n",
       " -5,\n",
       " 2,\n",
       " -2,\n",
       " -7,\n",
       " -5,\n",
       " -1,\n",
       " -5,\n",
       " -8,\n",
       " -3,\n",
       " -3,\n",
       " -5,\n",
       " 0,\n",
       " -1,\n",
       " -8,\n",
       " 3,\n",
       " -5,\n",
       " 1,\n",
       " -14,\n",
       " -4,\n",
       " -6,\n",
       " -9,\n",
       " -3,\n",
       " -4,\n",
       " -3,\n",
       " -10,\n",
       " -4,\n",
       " -5,\n",
       " -11,\n",
       " -10,\n",
       " -2,\n",
       " -9,\n",
       " -3,\n",
       " -1,\n",
       " -4,\n",
       " -5,\n",
       " -10,\n",
       " -5,\n",
       " -6,\n",
       " 0,\n",
       " -3,\n",
       " -5,\n",
       " -5,\n",
       " -10,\n",
       " 0,\n",
       " -1,\n",
       " -5,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -9,\n",
       " -16,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -2,\n",
       " 0,\n",
       " -11,\n",
       " -8,\n",
       " -2,\n",
       " -4,\n",
       " -3,\n",
       " -1,\n",
       " -17,\n",
       " 3,\n",
       " -9,\n",
       " -6,\n",
       " -9,\n",
       " -5,\n",
       " -4,\n",
       " -1,\n",
       " -17,\n",
       " -1,\n",
       " -2,\n",
       " 2,\n",
       " -8,\n",
       " -3,\n",
       " -5,\n",
       " -2,\n",
       " -7,\n",
       " -2,\n",
       " -13,\n",
       " -4,\n",
       " -7,\n",
       " -3,\n",
       " -1,\n",
       " -12,\n",
       " -1,\n",
       " -25,\n",
       " -8,\n",
       " 0,\n",
       " -15,\n",
       " -2,\n",
       " -2,\n",
       " -11,\n",
       " 2,\n",
       " -2,\n",
       " -6,\n",
       " -3,\n",
       " 0,\n",
       " -9,\n",
       " 0,\n",
       " -16,\n",
       " 6,\n",
       " -3,\n",
       " -2,\n",
       " -10,\n",
       " -2,\n",
       " -2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " -5,\n",
       " 0,\n",
       " -2,\n",
       " -2,\n",
       " -10,\n",
       " -13,\n",
       " -5,\n",
       " -7,\n",
       " 2,\n",
       " -5,\n",
       " -8,\n",
       " -4,\n",
       " -13,\n",
       " 0,\n",
       " -2,\n",
       " 0,\n",
       " -2,\n",
       " -5,\n",
       " -4,\n",
       " -11,\n",
       " 0,\n",
       " -2,\n",
       " 0,\n",
       " -7,\n",
       " -8,\n",
       " 0,\n",
       " -3,\n",
       " -4,\n",
       " -9,\n",
       " -5,\n",
       " -2,\n",
       " -8,\n",
       " -7,\n",
       " -2,\n",
       " 0,\n",
       " -4,\n",
       " -4,\n",
       " -2,\n",
       " -6,\n",
       " -5,\n",
       " -3,\n",
       " -6,\n",
       " -13,\n",
       " -4,\n",
       " -2,\n",
       " -14,\n",
       " -5,\n",
       " -11,\n",
       " -2,\n",
       " -3,\n",
       " -7,\n",
       " -2,\n",
       " 1,\n",
       " -9,\n",
       " -5,\n",
       " -3,\n",
       " -11,\n",
       " -1,\n",
       " -4,\n",
       " -6,\n",
       " 1,\n",
       " -6,\n",
       " -1,\n",
       " -4,\n",
       " -11,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -8,\n",
       " -1,\n",
       " -6,\n",
       " -3,\n",
       " -4,\n",
       " -3,\n",
       " -4,\n",
       " -5,\n",
       " -5,\n",
       " -6,\n",
       " -3,\n",
       " -11,\n",
       " -11,\n",
       " -1,\n",
       " -3,\n",
       " 0,\n",
       " -12,\n",
       " -6,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " -3,\n",
       " 0,\n",
       " -3,\n",
       " -9,\n",
       " -51,\n",
       " -8,\n",
       " 1,\n",
       " -17,\n",
       " -1,\n",
       " -9,\n",
       " -8,\n",
       " 0,\n",
       " -5,\n",
       " -10,\n",
       " -4,\n",
       " -4,\n",
       " -1,\n",
       " -4,\n",
       " -2,\n",
       " -4,\n",
       " 4,\n",
       " -6,\n",
       " 2,\n",
       " -1,\n",
       " -5,\n",
       " 0,\n",
       " -1,\n",
       " 9,\n",
       " -3,\n",
       " -3,\n",
       " -6,\n",
       " 1,\n",
       " -9,\n",
       " -15,\n",
       " -3,\n",
       " -4,\n",
       " 0,\n",
       " -3,\n",
       " -6,\n",
       " -7,\n",
       " -3,\n",
       " -6,\n",
       " -5,\n",
       " -6,\n",
       " -4,\n",
       " -42,\n",
       " 0,\n",
       " -2,\n",
       " -3,\n",
       " -2,\n",
       " -2,\n",
       " -11,\n",
       " -1,\n",
       " 0,\n",
       " -9,\n",
       " 2,\n",
       " -5,\n",
       " -3,\n",
       " 2,\n",
       " 1,\n",
       " -34,\n",
       " -4,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " -3,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -6,\n",
       " -14,\n",
       " -7,\n",
       " -1,\n",
       " -2,\n",
       " -6,\n",
       " -6,\n",
       " 1,\n",
       " -2,\n",
       " -7,\n",
       " -6,\n",
       " -9,\n",
       " -8,\n",
       " -3,\n",
       " -10,\n",
       " 1,\n",
       " -13,\n",
       " -8,\n",
       " 1,\n",
       " 0,\n",
       " -9,\n",
       " 0,\n",
       " -9,\n",
       " -6,\n",
       " -5,\n",
       " -4,\n",
       " -2,\n",
       " -2,\n",
       " -2,\n",
       " -12,\n",
       " -23,\n",
       " 3,\n",
       " -8,\n",
       " -4,\n",
       " -2,\n",
       " -1,\n",
       " -27,\n",
       " -3,\n",
       " -11,\n",
       " -5,\n",
       " -9,\n",
       " 0,\n",
       " -4,\n",
       " -1,\n",
       " -1,\n",
       " -4,\n",
       " -2,\n",
       " -9,\n",
       " -7,\n",
       " -12,\n",
       " -6,\n",
       " -10,\n",
       " -5,\n",
       " -2,\n",
       " 3,\n",
       " -14,\n",
       " 0,\n",
       " -3,\n",
       " -14,\n",
       " -1,\n",
       " -1,\n",
       " -6,\n",
       " -11,\n",
       " 3,\n",
       " -6,\n",
       " -5,\n",
       " -9,\n",
       " -1,\n",
       " -2,\n",
       " -3,\n",
       " -4,\n",
       " -4,\n",
       " -8,\n",
       " 0,\n",
       " -5,\n",
       " -4,\n",
       " -5,\n",
       " -4,\n",
       " -2,\n",
       " 2,\n",
       " -5,\n",
       " -5,\n",
       " -2,\n",
       " 0,\n",
       " -2,\n",
       " -4,\n",
       " 1,\n",
       " -6,\n",
       " -1,\n",
       " -7,\n",
       " 1,\n",
       " -2,\n",
       " -1,\n",
       " -5,\n",
       " -1,\n",
       " -6,\n",
       " -3,\n",
       " -3,\n",
       " -7,\n",
       " -14,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -4,\n",
       " -3,\n",
       " -3,\n",
       " -2,\n",
       " -3,\n",
       " -5,\n",
       " -13,\n",
       " 2,\n",
       " -2,\n",
       " -8,\n",
       " -2,\n",
       " -2,\n",
       " 0,\n",
       " -1,\n",
       " -6,\n",
       " -4,\n",
       " -7,\n",
       " -3,\n",
       " -5,\n",
       " -1,\n",
       " -8,\n",
       " -14,\n",
       " -5,\n",
       " -3,\n",
       " -1,\n",
       " -1,\n",
       " -4,\n",
       " -2,\n",
       " -2,\n",
       " -7,\n",
       " 0,\n",
       " -8,\n",
       " 2,\n",
       " 0,\n",
       " -2,\n",
       " -4,\n",
       " 3,\n",
       " -4,\n",
       " -4,\n",
       " -15,\n",
       " -1,\n",
       " 2,\n",
       " -4,\n",
       " 1,\n",
       " -1,\n",
       " -7,\n",
       " -4,\n",
       " -31,\n",
       " -6,\n",
       " -6,\n",
       " -4,\n",
       " -3,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " -6,\n",
       " -7,\n",
       " -8,\n",
       " -15,\n",
       " -3,\n",
       " -3,\n",
       " -5,\n",
       " -5,\n",
       " -7,\n",
       " -4,\n",
       " -10,\n",
       " -5,\n",
       " -4,\n",
       " -4,\n",
       " -6,\n",
       " -17,\n",
       " 2,\n",
       " 1,\n",
       " -9,\n",
       " -4,\n",
       " -5,\n",
       " -23,\n",
       " -10,\n",
       " -4,\n",
       " -1,\n",
       " -8,\n",
       " -15,\n",
       " -3,\n",
       " -5,\n",
       " -9,\n",
       " -5,\n",
       " -9,\n",
       " -20,\n",
       " -13,\n",
       " 2,\n",
       " -5,\n",
       " 0,\n",
       " -4,\n",
       " -9,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " -4,\n",
       " -11,\n",
       " -6,\n",
       " -6,\n",
       " 5,\n",
       " -3,\n",
       " 0,\n",
       " -7,\n",
       " -6,\n",
       " -6,\n",
       " -5,\n",
       " -5,\n",
       " -68,\n",
       " -5,\n",
       " 2,\n",
       " -3,\n",
       " -1,\n",
       " -3,\n",
       " -7,\n",
       " -2,\n",
       " -1,\n",
       " -3,\n",
       " -2,\n",
       " -4,\n",
       " -2,\n",
       " -1,\n",
       " -4,\n",
       " -9,\n",
       " -3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -4,\n",
       " -2,\n",
       " -16,\n",
       " -2,\n",
       " -6,\n",
       " -4,\n",
       " -2,\n",
       " -5,\n",
       " -2,\n",
       " -1,\n",
       " -7,\n",
       " -6,\n",
       " -2,\n",
       " 1,\n",
       " -2,\n",
       " -2,\n",
       " -4,\n",
       " -7,\n",
       " -2,\n",
       " 4,\n",
       " -3,\n",
       " -3,\n",
       " -1,\n",
       " -9,\n",
       " 2,\n",
       " -4,\n",
       " 2,\n",
       " -3,\n",
       " 5,\n",
       " -5,\n",
       " -4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " -4,\n",
       " -2,\n",
       " 0,\n",
       " 1,\n",
       " -3,\n",
       " -12,\n",
       " 0,\n",
       " -4,\n",
       " -1,\n",
       " -8,\n",
       " -15,\n",
       " -6,\n",
       " -2,\n",
       " -1,\n",
       " -3,\n",
       " -2,\n",
       " -13,\n",
       " 0,\n",
       " -3,\n",
       " 0,\n",
       " 1,\n",
       " -2,\n",
       " -7,\n",
       " -8,\n",
       " -2,\n",
       " -7,\n",
       " -6,\n",
       " -2,\n",
       " -7,\n",
       " -3,\n",
       " -2,\n",
       " -2,\n",
       " 0,\n",
       " -4,\n",
       " -9,\n",
       " -1,\n",
       " -3,\n",
       " -2,\n",
       " -7,\n",
       " -2,\n",
       " 2,\n",
       " 1,\n",
       " -5,\n",
       " -7,\n",
       " -1,\n",
       " 2,\n",
       " -2,\n",
       " 1,\n",
       " -3,\n",
       " -11,\n",
       " -3,\n",
       " -2,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -2,\n",
       " 9,\n",
       " -6,\n",
       " -2,\n",
       " 1,\n",
       " 0,\n",
       " -10,\n",
       " 0,\n",
       " 0,\n",
       " -8,\n",
       " 0,\n",
       " -11,\n",
       " 2,\n",
       " -2,\n",
       " -8,\n",
       " -76,\n",
       " -1,\n",
       " -9,\n",
       " 2,\n",
       " -10,\n",
       " 2,\n",
       " -4,\n",
       " -3,\n",
       " -1,\n",
       " -11,\n",
       " 0,\n",
       " -5,\n",
       " -5,\n",
       " 1,\n",
       " 0,\n",
       " -14,\n",
       " -15,\n",
       " -5,\n",
       " 0,\n",
       " -4,\n",
       " 2,\n",
       " -8,\n",
       " -5,\n",
       " -5,\n",
       " -11,\n",
       " -3,\n",
       " -43,\n",
       " -1,\n",
       " -6,\n",
       " -3,\n",
       " -4,\n",
       " -1,\n",
       " -4,\n",
       " -1,\n",
       " 0,\n",
       " -3,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " -12,\n",
       " 0,\n",
       " -4,\n",
       " 0,\n",
       " -3,\n",
       " -6,\n",
       " -1,\n",
       " -2,\n",
       " -15,\n",
       " -2,\n",
       " -8,\n",
       " -1,\n",
       " -2,\n",
       " -5,\n",
       " -6,\n",
       " 1,\n",
       " -8,\n",
       " -10,\n",
       " -5,\n",
       " -6,\n",
       " 0,\n",
       " -7,\n",
       " -15,\n",
       " -4,\n",
       " -2,\n",
       " -14,\n",
       " -8,\n",
       " 0,\n",
       " 0,\n",
       " -6,\n",
       " 1,\n",
       " -13,\n",
       " -2,\n",
       " -3,\n",
       " 0,\n",
       " -3,\n",
       " -4,\n",
       " -16,\n",
       " -5,\n",
       " -5,\n",
       " -5,\n",
       " -7,\n",
       " -4,\n",
       " 0,\n",
       " -10,\n",
       " -2,\n",
       " 2,\n",
       " -7,\n",
       " 0,\n",
       " -2,\n",
       " -7,\n",
       " -1,\n",
       " 4,\n",
       " -2,\n",
       " -15,\n",
       " -2,\n",
       " -1,\n",
       " -4,\n",
       " 0,\n",
       " -10,\n",
       " -2,\n",
       " -2,\n",
       " -6,\n",
       " 0,\n",
       " -4,\n",
       " -3,\n",
       " -14,\n",
       " -3,\n",
       " -17,\n",
       " 0,\n",
       " -6,\n",
       " -6,\n",
       " 2,\n",
       " -6,\n",
       " -8,\n",
       " 1,\n",
       " -4,\n",
       " -10,\n",
       " -8,\n",
       " -13,\n",
       " -1,\n",
       " 1,\n",
       " -5,\n",
       " -26,\n",
       " -7,\n",
       " -5,\n",
       " -3,\n",
       " -1,\n",
       " -3,\n",
       " 1,\n",
       " -11,\n",
       " -3,\n",
       " 0,\n",
       " -1,\n",
       " -3,\n",
       " -17,\n",
       " -4,\n",
       " 1,\n",
       " 0,\n",
       " -2,\n",
       " -3,\n",
       " -7,\n",
       " -3,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -6,\n",
       " -11,\n",
       " -17,\n",
       " 4,\n",
       " -15,\n",
       " -2,\n",
       " -2,\n",
       " -11,\n",
       " -9,\n",
       " -10,\n",
       " 0,\n",
       " -7,\n",
       " -5,\n",
       " -1,\n",
       " -2,\n",
       " 0,\n",
       " -4,\n",
       " -2,\n",
       " -4,\n",
       " 0,\n",
       " -3,\n",
       " 2,\n",
       " -2,\n",
       " -2,\n",
       " 1,\n",
       " -1,\n",
       " -9,\n",
       " -2,\n",
       " -2,\n",
       " -3,\n",
       " -9,\n",
       " -13,\n",
       " -3,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -5,\n",
       " -10,\n",
       " -2,\n",
       " -4,\n",
       " -6,\n",
       " -3,\n",
       " -2,\n",
       " -5,\n",
       " -3,\n",
       " -6,\n",
       " 0,\n",
       " -1,\n",
       " 2,\n",
       " -4,\n",
       " 5,\n",
       " -13,\n",
       " -11,\n",
       " -4,\n",
       " 0,\n",
       " -2,\n",
       " -4,\n",
       " -2,\n",
       " -2,\n",
       " -1,\n",
       " -2,\n",
       " 0,\n",
       " 0,\n",
       " -3,\n",
       " -5,\n",
       " -3,\n",
       " -2,\n",
       " 2,\n",
       " -3,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -3,\n",
       " -5,\n",
       " -5,\n",
       " -2,\n",
       " -8,\n",
       " -1,\n",
       " -4,\n",
       " -2,\n",
       " -3,\n",
       " -1,\n",
       " -1,\n",
       " 5,\n",
       " -4,\n",
       " 6,\n",
       " -3,\n",
       " 0,\n",
       " -7,\n",
       " -2,\n",
       " -3,\n",
       " -7,\n",
       " -5,\n",
       " -2,\n",
       " -8,\n",
       " 1,\n",
       " -3,\n",
       " -13,\n",
       " -4,\n",
       " -3,\n",
       " -3,\n",
       " 2,\n",
       " -4,\n",
       " -9,\n",
       " -6,\n",
       " 2,\n",
       " -1,\n",
       " -5,\n",
       " 0,\n",
       " -3,\n",
       " -12,\n",
       " -3,\n",
       " -6,\n",
       " -13,\n",
       " -2,\n",
       " -9,\n",
       " -1,\n",
       " -11,\n",
       " -11,\n",
       " 2,\n",
       " -9,\n",
       " -6,\n",
       " -10,\n",
       " -2,\n",
       " -7,\n",
       " -5,\n",
       " -5,\n",
       " 1,\n",
       " -3,\n",
       " -11,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " -8,\n",
       " -1,\n",
       " -3,\n",
       " -2,\n",
       " 1,\n",
       " 1,\n",
       " -6,\n",
       " -2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import Bing Liu's dictionary\n",
    "from nltk.corpus import opinion_lexicon\n",
    "pos_list_BL=set(opinion_lexicon.positive())\n",
    "neg_list_BL=set(opinion_lexicon.negative())\n",
    "\n",
    "def count_pos_neg (data, positive_dict, negative_dict): #define the function and give function the data \n",
    "# count of positive and negative words that appeared in each message\n",
    "# net count which is calculated by positive count subtracting negative count. \n",
    "    poscnt = []\n",
    "    negcnt = []\n",
    "    netcnt = []\n",
    "\n",
    "    for nrow in range(0,len(data)):\n",
    "        text = data[nrow]\n",
    "        \n",
    "        qa = 0\n",
    "        qb = 0\n",
    "\n",
    "        for word in positive_dict :\n",
    "            if (word in text) :\n",
    "                qa = qa + 1\n",
    "\n",
    "        for word in negative_dict :\n",
    "            if (word in text) :\n",
    "                qb = qb + 1\n",
    "\n",
    "        qc = qa - qb\n",
    "\n",
    "        poscnt.append(qa)\n",
    "        negcnt.append(qb)\n",
    "        netcnt.append(qc)\n",
    "\n",
    "    return (poscnt, negcnt, netcnt)\n",
    "\n",
    "\n",
    "#define bing liu's data and count positive, negative a net words \n",
    "#data_BL = data.copy()\n",
    "#data_BL['poscnt_BL'], data_BL['negcnt_BL'], data_BL['netcnt_BL'] = count_pos_neg(data.MESSAGE.str.lower(), pos_list_BL, neg_list_BL)\n",
    "\n",
    "#data_BL[['MESSAGE','poscnt_BL','negcnt_BL','netcnt_BL']].head(10)\n",
    "_, _, bow_train_features = count_pos_neg(list(train_corpus), pos_list_BL, neg_list_BL)\n",
    "_, _, bow_test_features = count_pos_neg(list(test_corpus), pos_list_BL, neg_list_BL)\n",
    "\n",
    "bow_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bag of words features' vectorizer and get features\n",
    "bow_vectorizer=CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "bow_train_features = bow_vectorizer.fit_transform(train_corpus)\n",
    "bow_test_features = bow_vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1739x106539 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 239987 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build tfidf features' vectorizer and get features\n",
    "tfidf_vectorizer=TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=(1,1))\n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(train_corpus)  \n",
    "tfidf_test_features = tfidf_vectorizer.transform(test_corpus) \n",
    "\n",
    "tfidf_test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13724009,  0.17637639,  0.29806627, ..., -0.25720087,\n",
       "        -0.01940251,  0.60300929],\n",
       "       [-0.3018132 ,  0.12842271,  0.50557573, ..., -0.02840612,\n",
       "         0.09384182,  0.84370447],\n",
       "       [ 1.34982803,  1.03344341, -0.46713   , ...,  0.11218975,\n",
       "        -0.64772561,  0.51497502],\n",
       "       ...,\n",
       "       [ 1.06917356,  1.15761293, -0.70515634, ...,  0.01918962,\n",
       "        -0.90619834,  0.62072976],\n",
       "       [-0.19825279,  0.17823381,  0.33343152, ..., -0.05488258,\n",
       "         0.09737869,  0.68000222],\n",
       "       [-0.75171329,  0.63753763, -0.46999577, ...,  0.06015024,\n",
       "        -0.06930079,  0.43344649]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize documents for word2vec\n",
    "tokenized_train = [nltk.word_tokenize(text)\n",
    "                   for text in train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text)\n",
    "                   for text in test_corpus]  \n",
    "\n",
    "# build word2vec model                   \n",
    "wv_model = gensim.models.Word2Vec(tokenized_train,\n",
    "                               vector_size=200,                          #set the size or dimension for the word vectors \n",
    "                               window=60,                        #specify the length of the window of words taken as context\n",
    "                               min_count=10)                   #ignores all words with total frequency lower than 10\n",
    "\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector \n",
    "   \n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "# averaged word vector features from word2vec\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=wv_model,\n",
    "                                                 num_features=200)                   \n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=wv_model,\n",
    "                                                num_features=200) \n",
    "avg_wv_test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to evaluate our classification models based on four metrics\n",
    "# This defined function is also useful in other cases. This is comparing test_y and pred_y. \n",
    "# Both contain 1s and 0s.\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    metrics_dict = dict(zip([\"accuracy\", \"precision\", \"recall\", \"f1\"], [None]*4))\n",
    "    #metrics_dict = {i:None for i in [\"accuracy\", \"precision\", \"recall\", \"f1\"]}\n",
    "    for m in metrics_dict.keys():\n",
    "        exec('''metrics_dict['{}'] = np.round(                                                    \n",
    "                        metrics.{}_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        2)'''.format(m, m))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an Easy-to-use Function for Train/Test/Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that trains the model, performs predictions and evaluates the predictions\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels,\n",
    "                                title):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    # evaluate model prediction performance   \n",
    "    '''get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)'''\n",
    "    print(title)\n",
    "    print(metrics.classification_report(test_labels,predictions))\n",
    "    return predictions, get_metrics(true_labels=test_labels, predicted_labels=predictions)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: \n",
    "## 2) Compare 3 Classifiers \n",
    "### Report Precision, Recall, F1, Accuracy by Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # import naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB #another naive bayes - for Word2Vec \n",
    "from sklearn.tree import DecisionTreeClassifier # import Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test on BOW Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes on BOW\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1164\n",
      "           1       0.99      0.78      0.87       575\n",
      "\n",
      "    accuracy                           0.92      1739\n",
      "   macro avg       0.95      0.89      0.91      1739\n",
      "weighted avg       0.93      0.92      0.92      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign naive bayes function to an object\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# predict and evaluate naive bayes\n",
    "mnb_bow_predictions, mnb_bow_metrics = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels, title=\"Naive Bayes on BOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree on BOW\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1164\n",
      "           1       0.93      0.91      0.92       575\n",
      "\n",
      "    accuracy                           0.95      1739\n",
      "   macro avg       0.94      0.94      0.94      1739\n",
      "weighted avg       0.95      0.95      0.95      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign decision tree function to an object\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# predict and evaluate decision tree\n",
    "dt_bow_predictions, dt_bow_metrics = train_predict_evaluate_model(classifier=dt,\n",
    "                                                               train_features=bow_train_features,\n",
    "                                                               train_labels=train_labels,\n",
    "                                                               test_features=bow_test_features,\n",
    "                                                               test_labels=test_labels, title=\"Decision Tree on BOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest on BOW\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1164\n",
      "           1       0.99      0.92      0.95       575\n",
      "\n",
      "    accuracy                           0.97      1739\n",
      "   macro avg       0.98      0.96      0.97      1739\n",
      "weighted avg       0.97      0.97      0.97      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign random forest function to an object\n",
    "rf = RandomForestClassifier(criterion=\"entropy\")\n",
    "\n",
    "# predict and evaluate random forest\n",
    "rf_bow_predictions, rf_bow_metrics = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels, title=\"Random Forest on BOW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test on TFIDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes on TFIDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      1164\n",
      "           1       0.99      0.64      0.78       575\n",
      "\n",
      "    accuracy                           0.88      1739\n",
      "   macro avg       0.92      0.82      0.85      1739\n",
      "weighted avg       0.90      0.88      0.87      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate naive bayes\n",
    "mnb_tfidf_predictions, mnb_tfidf_metrics = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels, title=\"Naive Bayes on TFIDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree on TFIDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1164\n",
      "           1       0.93      0.91      0.92       575\n",
      "\n",
      "    accuracy                           0.95      1739\n",
      "   macro avg       0.94      0.94      0.94      1739\n",
      "weighted avg       0.95      0.95      0.95      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate decision tree\n",
    "dt_tfidf_predictions, dt_tfidf_metrics = train_predict_evaluate_model(classifier=dt,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels,  title=\"Decision Tree on TFIDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest on TFIDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1164\n",
      "           1       0.99      0.90      0.94       575\n",
      "\n",
      "    accuracy                           0.96      1739\n",
      "   macro avg       0.97      0.95      0.96      1739\n",
      "weighted avg       0.97      0.96      0.96      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate random forest\n",
    "rf_tfidf_predictions, rf_tfidf_metrics = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels,  title=\"Random Forest on TFIDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test on Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian on Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1164\n",
      "           1       0.94      0.83      0.88       575\n",
      "\n",
      "    accuracy                           0.93      1739\n",
      "   macro avg       0.93      0.90      0.91      1739\n",
      "weighted avg       0.93      0.93      0.92      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign GaussianNB function to an object\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# predict and evaluate naive bayes\n",
    "gnb_avgwv_predictions, gnb_avgwv_metrics = train_predict_evaluate_model(classifier=gnb,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels,  title=\"Gaussian on Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree on Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1164\n",
      "           1       0.95      0.94      0.94       575\n",
      "\n",
      "    accuracy                           0.96      1739\n",
      "   macro avg       0.96      0.96      0.96      1739\n",
      "weighted avg       0.96      0.96      0.96      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate decision tree\n",
    "dt_avgwv_predictions, dt_avgwv_metrics = train_predict_evaluate_model(classifier=dt,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels,  title=\"Decision Tree on Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest on Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1164\n",
      "           1       0.99      0.97      0.98       575\n",
      "\n",
      "    accuracy                           0.99      1739\n",
      "   macro avg       0.99      0.98      0.98      1739\n",
      "weighted avg       0.99      0.99      0.99      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate random forest\n",
    "rf_avgwv_predictions, rf_avgwv_metrics = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels,  title=\"Random Forest on Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: \n",
    "## (2) Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Performance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mAccuracy Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Gaussian Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.92                   NaN           0.95           0.97\n",
      "TFIDF                0.88                   NaN           0.95           0.96\n",
      "Word2Vec              NaN                  0.93           0.96           0.99\n",
      "\n",
      "\u001b[1;31mPrecision Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Gaussian Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.99                   NaN           0.93           0.99\n",
      "TFIDF                0.99                   NaN           0.93           0.99\n",
      "Word2Vec              NaN                  0.94           0.95           0.99\n",
      "\n",
      "\u001b[1;31mRecall Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Gaussian Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.78                   NaN           0.91           0.92\n",
      "TFIDF                0.64                   NaN           0.91           0.90\n",
      "Word2Vec              NaN                  0.83           0.94           0.97\n",
      "\n",
      "\u001b[1;31mF1 Score Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Gaussian Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.87                   NaN           0.92           0.95\n",
      "TFIDF                0.78                   NaN           0.92           0.94\n",
      "Word2Vec              NaN                  0.88           0.94           0.98\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary that stores all the accuracy information\n",
    "performance_dict = {}\n",
    "\n",
    "for me in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "    performance_dict[me] = {}\n",
    "    for m in [\"mnb\",\"gnb\", \"dt\",\"rf\"]:\n",
    "        performance_dict[me][m] = {}\n",
    "        for f in [\"bow\",\"tfidf\",\"avgwv\"]:\n",
    "            try:\n",
    "                exec('performance_dict[\"{}\"][\"{}\"][\"{}\"] = {}_{}_metrics[\"{}\"]'.format(me, m, f, m, f, me))\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "#Accuracy Matrix\n",
    "print(\"\\n\\033[1;31mAccuracy Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"accuracy\"]).rename(columns={\"mnb\":\"Naive Bayes\",\n",
    "                                            \"gnb\": \"Gaussian Naive Bayes\",\n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#Precision Matrix\n",
    "print(\"\\n\\033[1;31mPrecision Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"precision\"]).rename(columns={\"mnb\":\"Naive Bayes\",\n",
    "                                            \"gnb\": \"Gaussian Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#Recall Matrix\n",
    "print(\"\\n\\033[1;31mRecall Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"recall\"]).rename(columns={\"mnb\":\"Naive Bayes\",\n",
    "                                            \"gnb\": \"Gaussian Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#F1 Score Matrix\n",
    "print(\"\\n\\033[1;31mF1 Score Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"f1\"]).rename(columns={\"mnb\":\"Naive Bayes\",\n",
    "                                            \"gnb\": \"Gaussian Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "## Calculate the total cost and expected cost (per email) based on the confusion matrix you obtained in Question 1. Assume the cost for each miss-classified email from Spam to Non-spam is 5, and from Non-spam to Spam is 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-85515dc34bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#set up inputs for equation to find total and expected cost (per email) based on confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m features = [[np.array(bow_train_features).reshape((len(bow_train_features),1)),\n\u001b[0m\u001b[0;32m      4\u001b[0m              np.array(bow_test_features).reshape((len(bow_test_features),1)), \"Binary\"],\n\u001b[0;32m      5\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mtfidf_train_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_test_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TFIDF\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[0;32m    292\u001b[0m                         \" or shape[0]\")\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "#set up inputs for equation to find total and expected cost (per email) based on confusion matrix\n",
    "classifiers = [mnb, gnb, dt, rf]\n",
    "features = [[np.array(bow_train_features).reshape((len(bow_train_features),1)),\n",
    "             np.array(bow_test_features).reshape((len(bow_test_features),1)), \"Binary\"],\n",
    "            [tfidf_train_features, tfidf_test_features, \"TFIDF\"],\n",
    "            [np.array(avg_wv_train_features).shape(avg_wv_train_features),1, \n",
    "            np.array(avg_wv_test_features).shape(avg_wv_test_features),1, \"Word2Vec\"]]\n",
    "            \n",
    "#unfortunately could not get the features to run properly, even though I did before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected costs from the Confusion Matrix\n",
    "for c in classifiers:\n",
    "    for f in features:\n",
    "        # predict and evaluate naive bayes\n",
    "        try:\n",
    "            pred, metric = train_predict_evaluate_model(classifier=c,\n",
    "                                               train_features=f[0],\n",
    "                                               train_labels=train_labels,\n",
    "                                               test_features=f[1],\n",
    "                                               test_labels=test_labels,\n",
    "                                                title=str(type(c)) + f[2])\n",
    "            # Equation for expected costs\n",
    "            costs = [100*cost if cost == 1 else -5*cost for cost in pred - test_labels]\n",
    "            results.append([pred,metric, costs])\n",
    "        except:\n",
    "            pass\n",
    "#print results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on your observation, please analyze which combination of feature and classifier is the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the results from the confusion matrix and previous observations, it appears that the Random Forest classifier on the Word2Vec feature are the best for this dataset. The Random Forest Classifier in itself had about an avreage of .98 or 98% accuracy, while Word2Vec was around .95 or 95%. I came to this conclusion after comparing the accuracy, precision, recall and f-score for for each feature and classifier. Word2Vec groups words in a dataset that are similar to each other, thus outputting vectors representative of words in the corpus. It further groups vectors that are similar to eachother into a 'vectorspace' based on context. Overall, for this dataset of Spam Emails, I believe the Word2Vec generates precise vectors representative of what groupings of words or vectors would be considered \"spam\" over non-spam emails. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
